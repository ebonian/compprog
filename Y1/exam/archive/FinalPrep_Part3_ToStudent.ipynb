{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGaIK511__YC"
   },
   "source": [
    "# Final Preparation Part3 (Language Model)\n",
    "Objective: \n",
    "\n",
    "\n",
    "*   Lecture8: Dictionary\n",
    "*   Lecture9: Nested Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce2qwWMvuKhz"
   },
   "source": [
    "[Link to problem](https://docs.google.com/document/d/1yliw1he71QN_laxYi9x5zjv68jM-UNXh19ccDX7C29E/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "hP7snVfobMpY"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# FUNCTIONS (FILL CODE IN THIS PART)\n",
    "#############################################\n",
    "def train_language_model(data):\n",
    "  # Input:\n",
    "  #    data: a list of sentences\n",
    "  # Return:\n",
    "  #    model: a dictionary which contains\n",
    "  #           (1) unk: default value for unknown word\n",
    "  #           (2) unigram: a dictionary of unigram counts\n",
    "  #           (3) bigram: a dictionary of bigram counts\n",
    "  model = dict()\n",
    "  unigram = dict()\n",
    "  bigram = dict()\n",
    "  unk = 0\n",
    "\n",
    "  a = [sentence.split() for sentence in data]\n",
    "  unk = 1 / len([item for sublist in a for item in sublist])\n",
    "\n",
    "  # fill your code here\n",
    "  data = [sentence.split() for sentence in data]\n",
    "  for sentence in data:\n",
    "    for i in range(len(sentence)):\n",
    "      # unigram\n",
    "      unigram[sentence[i]] = unigram.get(sentence[i], 0) + 1\n",
    "\n",
    "      # bigram\n",
    "      if i < len(sentence) - 1:\n",
    "        if (sentence[i], sentence[i + 1]) not in bigram:\n",
    "          bigram[(sentence[i], sentence[i + 1])] = 1\n",
    "        else:\n",
    "          bigram[(sentence[i], sentence[i + 1])] += 1\n",
    "\n",
    "  model['unk'] = unk\n",
    "  model['unigram'] = unigram\n",
    "  model['bigram'] = bigram\n",
    "  return model\n",
    "\n",
    "def compute_sentence(sentence, model):\n",
    "  # Input:\n",
    "  #    sentence: an input string to be calculated probability\n",
    "  #    model: language model\n",
    "  # Return:\n",
    "  #    probability: probability of sentence to occur\n",
    "  word = sentence.split()\n",
    "\n",
    "  for i in range(len(word)):\n",
    "    if i < len(word) - 1:\n",
    "      word_pair = word[i], word[i + 1]\n",
    "      print(model[\"bigram\"][word_pair])\n",
    "\n",
    "  probability = 1.0\n",
    "  return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8rl4rqt-G6bw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 6 vocabularies\n",
      "- 9 word pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# MAIN (DO NOT CHANGE THIS PART)\n",
    "#############################################\n",
    "\n",
    "# Step1: read data\n",
    "data = [\"<s> I am Sam </s>\", \"<s> Sam I am </s>\", \"<s> I am not Sam </s>\"]\n",
    "\n",
    "# Step2: train language model\n",
    "model = train_language_model(data)\n",
    "print('-', len(model['unigram']), 'vocabularies')\n",
    "print('-', len(model['bigram']), 'word pairs')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "error",
     "timestamp": 1669342523874,
     "user": {
      "displayName": "Duangdao Wichadakul",
      "userId": "07038766120941488824"
     },
     "user_tz": -420
    },
    "id": "SBvKNMgjrHvh",
    "outputId": "4c59b495-4479-48fa-a1ff-28c5b8465a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "Case1: Prob of <s> I am Sam </s> = 1.0\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('I', 'love')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tanadon\\Coding\\ICE-Computer-Programming\\tutoring\\final\\FinalPrep_Part3_ToStudent.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Case2: The prob should be 0.01235\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sentence \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<s> I love Sam </s>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m probability \u001b[39m=\u001b[39m compute_sentence(sentence, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCase2: Prob of\u001b[39m\u001b[39m'\u001b[39m,sentence, \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mround\u001b[39m(probability,\u001b[39m5\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Case3: The prob should be 0.16667\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Tanadon\\Coding\\ICE-Computer-Programming\\tutoring\\final\\FinalPrep_Part3_ToStudent.ipynb Cell 5\u001b[0m in \u001b[0;36mcompute_sentence\u001b[1;34m(sentence, model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m   \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(word) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     word_pair \u001b[39m=\u001b[39m word[i], word[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mprint\u001b[39m(model[\u001b[39m\"\u001b[39;49m\u001b[39mbigram\u001b[39;49m\u001b[39m\"\u001b[39;49m][word_pair])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m probability \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tanadon/Coding/ICE-Computer-Programming/tutoring/final/FinalPrep_Part3_ToStudent.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m probability\n",
      "\u001b[1;31mKeyError\u001b[0m: ('I', 'love')"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# TEST CASES (DO NOT CHANGE THIS PART)\n",
    "#############################################\n",
    "i = 0\n",
    "# Case1: The prob should be 0.14815\n",
    "sentence = \"<s> I am Sam </s>\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case1: Prob of',sentence, \"=\", round(probability,5))\n",
    "\n",
    "# Case2: The prob should be 0.01235\n",
    "sentence = \"<s> I love Sam </s>\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case2: Prob of',sentence, \"=\", round(probability,5))\n",
    "\n",
    "# Case3: The prob should be 0.16667\n",
    "sentence = \"\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case5: Prob of empty string =', round(probability,5))\n",
    "\n",
    "# Case4: What is the prob?\n",
    "sentence = \"<s> I am not Sam </s>\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case4: Prob of',sentence, \"=\", round(probability,5))\n",
    "\n",
    "# Case5: What is the prob?\n",
    "sentence = \"<s> Sam not I </s>\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case5: Prob of',sentence, \"=\", round(probability,5))\n",
    "\n",
    "# Case6: What is the prob?\n",
    "sentence = \"<s>\"\n",
    "probability = compute_sentence(sentence, model)\n",
    "print('Case6: Prob of',sentence, \"=\", round(probability,5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
